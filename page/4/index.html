<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"77philosophia.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Garfield&#39;s blog">
<meta property="og:url" content="http://77philosophia.github.io/page/4/index.html">
<meta property="og:site_name" content="Garfield&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="philosophia">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://77philosophia.github.io/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Garfield's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Garfield's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://77philosophia.github.io/2024/05/20/frisbee-pickup/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="philosophia">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garfield's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/05/20/frisbee-pickup/" class="post-title-link" itemprop="url">frisbee-pickup</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-05-20 23:43:40" itemprop="dateCreated datePublished" datetime="2024-05-20T23:43:40+08:00">2024-05-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-05-21 00:17:26" itemprop="dateModified" datetime="2024-05-21T00:17:26+08:00">2024-05-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="当参加飞盘的比赛">当参加飞盘的比赛</h2>
<p>​
距离接触飞盘已经两年了，中间受伤的一年没有如何运动，我几乎踩中了很多不利的因素：</p>
<ul>
<li>错过最好的学校的大段时间训练和有场地、伙伴练习的机会，我玩飞盘已经是研究生快毕业的时候</li>
<li>北漂互联网，在北京参加飞盘活动路上时间花费很多</li>
<li>几乎没什么体育底子</li>
</ul>
<p>​ 为什么还要玩</p>
<ul>
<li>上手容易，以及飞盘的规则是no touch，真的很不喜欢人碰我</li>
<li>锻炼身体的动力</li>
</ul>
<p>​
我不是很厉害的选手，所以没有长期训练的队伍，很多时候都在打皮卡。花了很多时间，当了很多次炮灰得到的感悟：</p>
<ul>
<li>在皮卡的小比赛要珍惜每一次拿盘的机会，要去捡盘，一定要克服被打击而畏缩的惯性。我真的看到太多太多次，在皮卡，男生让女生不要捡盘，“让我捡”、“你不要碰”，而很多女生甚至视之为理所当然，“因为自己没有能力”，“会让队伍失分”，所以我们只能寄希望于好的队伍好的团体氛围。
<ul>
<li>1.皮卡的目的是自己的进步，如果用一个优化函数定义自己的目标，那就是在短短的场上几十分钟的时间内，将自己暴露在尽可能多的尝试和失败当中。这个游戏规则其实很简单，练习越多，进步越快。在皮卡中队伍的输赢本不应该成为一个阻碍，考虑也只是均衡双方力量让比赛尽可能有竞争力的进行下去。</li>
<li>2.能力不应该成为不控盘的理由。我多么希望自己能在早期就明白这个道理，在男生让我只是传dump给他的时候，在我即使捡盘也有近处一个男生让我直接给他的时候，在初次进入一个领域知道并坚持自己享有和其他人同等竞争的机会和权利，不要轻易放弃。</li>
</ul></li>
<li>参加一个比赛，跟着一个队伍“容易成为炮灰”，这种情况很多时候表示为：
<ul>
<li>喊你的时候对方理由一般是缺人，但是后面喊的人越来越多，越多的人数分摊有限的上场机会。尤其是认识的人，往往不好“问的太多”显得很难对付。</li>
<li>如果去参加一个皮卡的队伍，应该约定好你们准备招募多少个人，可以保证多少分的上场机会。（我在这方面当炮灰太多次了，因为没有队伍，因为处于弱势，所以我一度觉得这是我不得不接受的规则。直到后来我开始怀疑这个想法，如果我不接受这件事情就不会发生。我宁愿不参加比赛也不接受不平等的忽视和上场机会。不比赛依旧有很多方法可以去训练，依然可以进步。</li>
</ul></li>
<li>国内的很多比赛都是34
43ABBA的赛制轮回，但是实际比赛我却发现真正执行到底的比赛不多。很多时候都是：“我们女生不够”让对方队伍不好拒绝，<strong>其实这种情况的解决方案本应该是女生不够的队伍可以认输</strong>，事实上每一次妥协都是在牺牲女性盘友的上场机会。因为对“人数不够”的场景的默认，虽然有这样的规则，女盘手的缺失不成为一个问题。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://77philosophia.github.io/2020/08/18/nuscenes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="philosophia">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garfield's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/18/nuscenes/" class="post-title-link" itemprop="url">nuscenes</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-18 12:19:50" itemprop="dateCreated datePublished" datetime="2020-08-18T12:19:50+08:00">2020-08-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-05-20 23:24:11" itemprop="dateModified" datetime="2024-05-20T23:24:11+08:00">2024-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>学习建议官方的devkit，由于nuscenes按照token索引数据，不建议自己读取jason文件，而是根据官方函数使用其接口。探索数据集用Mini数据集很方便。</p>
<h3 id="item名词">1.item名词</h3>
<p>nuscenes数据集把各个类型的数据分别组织成了一个table.比如scene车移动场景、sample关键帧、instance实例、category类别等等。对于每一个数据都有一个唯一的token来索引到这个数据。所以我们得到数据的过程就是根据官方提供的接口和函数找接口取数据的过程。具体的栏目有：</p>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 77%" />
</colgroup>
<thead>
<tr>
<th>Item</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scene</td>
<td>整个数据集一共1000个场景，Mini的有10个。每20s是一个场景</td>
</tr>
<tr>
<td>sample</td>
<td>An annotated snapshot of a scene at a particular timestamp</td>
</tr>
<tr>
<td>Sample_data</td>
<td>Data collected from a particular sensor.</td>
</tr>
<tr>
<td>Instance</td>
<td>Enumeration of all object instance we observed</td>
</tr>
<tr>
<td>Category</td>
<td>Taxonomy of object categories (e.g. vehicle, human).</td>
</tr>
<tr>
<td>Attribute</td>
<td>Property of an instance that can change while the category remains
the same.</td>
</tr>
<tr>
<td>Visibility</td>
<td>可见性</td>
</tr>
<tr>
<td>Sensor</td>
<td>nuscenes有6个camera,1个lidar,5个radar.我们主要做的detection任务只涉及到camera.所以接下来只会涉及到camera.</td>
</tr>
<tr>
<td>Calibrated sensor</td>
<td>Definition of a particular sensor as calibrated on a particular
vehicle.进行坐标转换的时候主要用到的数据，上面的sensor其实只有一些基本信息，没有坐标转换参数。所以要进行坐标转换工作主要使用这类数据</td>
</tr>
</tbody>
</table>
<h3 id="nuscenes涉及的几个坐标系">2. Nuscenes涉及的几个坐标系</h3>
<ul>
<li>global坐标系：一般的bbox，ego
pose都是在全局坐标系下给出的，可以理解为人为设定的一个坐标系，具体也不知道在哪儿。</li>
<li>ego坐标系：车体坐标系，注意calibrated
sensor相机的外参是相对车体给出的。</li>
<li>摄像机坐标系</li>
</ul>
<h3 id="scene">3. Scene</h3>
<p><code>nusc.list_scenes()</code> 方法列举出所有的scene。</p>
<p><code>nusc.scene</code> 返回列表，可以根据下标去索引具体的scene.</p>
<p><img src="/2020/08/18/nuscenes/图片1.png" /></p>
<h3 id="sample">4.Sample</h3>
<p>在scenes中，每半秒（2
HZ）标注一次数据就是sample。所以sample就是那些有标注的帧。附官方定义：各个传感器有自己的时间线，一致对上的就是关键帧。</p>
<p>•We define sample as an annotated keyframe of a scene at a given
timestamp. A keyframe is a frame where the time-stamps of data from all
the sensors should be very close to the time-stamp of the sample it
points to.</p>
<p><code>my_sample = nusc.get('sample',first_sample)</code></p>
<p><img src="/2020/08/18/nuscenes/图片2.png" /></p>
<p><code>nusc.list_scene</code> 列举出所有的场景</p>
<p><code>nusc.list_sample(my_sample_token["token"])</code> 列举出related
sample_data keyframes and sample_annotation associated with a sample</p>
<h3 id="sample_data">5. Sample_data</h3>
<p>从一个sample中具体取出哪路相机数据。</p>
<p><code>my_sample['data']</code> 列举出12个token,分别是6 camera 5 radar
1 lidar</p>
<p><img src="/2020/08/18/nuscenes/图片3.png" /></p>
<p>具体取出某个sensor的数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sensor = &#x27;CAM_FRONT&#x27;</span><br><span class="line">Cam_front_data = nusc.get(&#x27;sample_data&#x27;,my_sample[&#x27;data&#x27;][sensor])</span><br></pre></td></tr></table></figure>
<p><img src="/2020/08/18/nuscenes/图片4.png" /></p>
<p>根据sample_data的token取出路径、annotationh和相机内参的接口，检测任务的dataloader很好用.这个函数tutorial没有给，源代码有。传入的第二个可见性的参数是关于bbox的，具体可看源代码。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_path,box_list,cam_intrinsic = nusc.get_sample_data(token,visibility)</span><br></pre></td></tr></table></figure>
<p>可视化某一个sample_data:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nusc.render_sample_data(cam_front_data[&#x27;token&#x27;])</span><br></pre></td></tr></table></figure>
<p><img src="/2020/08/18/nuscenes/图片6.png" /></p>
<h3 id="sample_annotation">6. Sample_annotation</h3>
<p>sample_annotation refers to any bounding box defining the position of
an object seen in a sample. All location data is given with respect to
the global coordinate
system.注意注释数据的位置信息都是相对于全局坐标系给出的。</p>
<p><img src="nuscenes/图片5.png" style="zoom:75%;" /></p>
<p>可视化sample_annotation:</p>
<p><img src="/2020/08/18/nuscenes/图片12.png" /></p>
<h3 id="instance">7.instance</h3>
<p>Object instance are instances that need to be detected or tracked by
an AV.</p>
<p><code>nusc.instance</code> 返回instance的列表，可以通过下标索引。</p>
<h3 id="category">8. category</h3>
<p><code>nusc.list_categories()</code></p>
<p><img src="/2020/08/18/nuscenes/图片8.png" /></p>
<h3 id="attribute">9. attribute</h3>
<p>An attribute is a property of an instance that may change throughout
different parts of a scene while the category remains the same.</p>
<p><img src="/2020/08/18/nuscenes/图片9.png" /></p>
<h3 id="visibility">10. visibility</h3>
<p>visibility可视化及描述：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">anntoken=<span class="string">&#x27;a7d0722bce164f88adf03ada491ea0ba&#x27;</span></span><br><span class="line">visibility_token = nusc.get(<span class="string">&#x27;sample_annotation&#x27;</span>,anntoken)[<span class="string">&#x27;visibility_token&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Visibility:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(nusc.get(<span class="string">&#x27;visibility&#x27;</span>,visibility_token)))</span><br><span class="line">nusc.render_annotation(anntoken)</span><br></pre></td></tr></table></figure>
<p>Visibility: {'description': 'visibility of whole object is between 80
and 100%', 'token': '4', 'level': 'v80-100'}</p>
<p><img src="/2020/08/18/nuscenes/图片10.png" /></p>
<h3 id="sensor">11. sensor</h3>
<p>1 lidar, 5 radar, 6 cameras</p>
<h3 id="calibrated_sensor">12. Calibrated_sensor</h3>
<p>calibrated_sensor consists of the definition of a particular sensor
(lidar/radar/camera) as calibrated on a particular vehicle.
注意外参是相对<strong>ego vehicle body frame</strong>得到的。</p>
<p><img src="/2020/08/18/nuscenes/图片14.png" /></p>
<p>3D bounding box坐标：X points forward, Y to the left, Z up</p>
<p>理解“with respect to ego vehicle body
frame”，就是说我相机坐标系中的坐标转换到ego vehicle，就是</p>
<p><span class="math display">\[(\left[ \begin{array}{l} x_{ego}\\\\
y_{ego}\\\\ z_{ego} \end{array} \right] = R\left[ \begin{array}{l}
x_{camera}\\\\ y_{camera}\\\\ z_{camera} \end{array} \right] +
T)\]</span></p>
<p>相应的把ego vehicle坐标系下的bbox转换到sensor coord system就是：</p>
<p><img src="/2020/08/18/nuscenes/图片15.png" /></p>
<h3 id="ego_pose">13. Ego_pose</h3>
<p>go_pose contains information about the location (encoded in
translation) and the orientation (encoded in rotation) of the ego
vehicle, with respect to the <strong>global coordinate
system</strong>.</p>
<p>ego_pose的数量和sample_data是一样的，这两者是一一对应的关系。<u>其实我有点不懂为什么每一个sample_data对应有一个ego_pose，六路相机也就是一个sample不应该对应一个ego
pose吗</u></p>
<p>•描述的是车体自己（x forward,y left,z
up）相对于全局坐标系的旋转R和平移T。这个R通过四元数给出。</p>
<p>•理解ego pose的R和T都是相对于（with respect
to）全局坐标系这句话;也就是ego坐标系中的一个坐标要变换到全局坐标系中就是</p>
<p><span class="math inline">\(\left[ \begin{array}{l} x_{global}\\\\
y_{global}\\\\ z_{global} \end{array} \right] = R\left[ \begin{array}{l}
x_{ego}\\\\ y_{ego}\\\\ z_{ego} \end{array} \right] + T\)</span></p>
<p>其中公式左边是全局坐标系中的坐标。</p>
<h3
id="nuscenes评测只涉及detection方面">14.nuscenes评测（只涉及detection方面）</h3>
<p>•Nuscenes的评测程序可以在devkit中的eval找到。</p>
<p>•README中规定了相应的sample_result的格式。prediction的结果要按照规定格式组织jason文件。sample_result的表和sample_annotation的表设计为一样的，所以完全可以用sample_annotation的工具和接口去操作sample_result.同时注意生成的结果即使没有识别出框，必须存在相应的token.</p>
<p>•虽然nuscenes训练有23类，但是评测处理similar和rare的类别，考虑到每一类的frequency,最终只归纳了10类，并且每一类有个detection
range(meters)。超过这个距离识别出来的框忽略。</p>
<p><a
target="_blank" rel="noopener" href="https://www.nuscenes.org/nuscenes#data-annotation">这个链接可以看到数据集各个类别的频率</a></p>
<h5 id="预处理">1.预处理</h5>
<p>GT和predition bboxes:</p>
<p>•超过距离的移除；</p>
<p>•Bikes和motorcycle在bike-rack里面的没有被注释也忽略</p>
<p>GT bboxes:</p>
<p>•没有Lidar和radar点的被移除，不能确保在当前frame是可见的</p>
<h5 id="评测矩阵">2.评测矩阵</h5>
<p>mAP:
一般的物体检测选择IOU来做匹配标准和评价阈值，Nuscenes选取的是xy平面bbox距离ego的距离（也就是深度距离）来作为标准，选择最小的距离匹配。选取{0.5,1,2,4}作为距离阈值（相当于原来的IOU@0.3,0.5,0.7），计算AP的时候只选取precision和recall&gt;0.1的点进行计算，当然由于没有计算&lt;0.1的部分会做一个归一化的操作。</p>
<p>TP metircs：其他因素的误差矩阵。Average of translation, velocity,
scale, orientation and attribute errors.</p>
<p>NDS(nuscenes detection score): the weighted sum of the
above。评价总分，mAP占50%，TP中的五类误差各占权重10%。其中TP
metrics统计的是误差值，到衡量得分存在一个转化关系：<code>TP score = max(1-TP_error,0.0)</code></p>
<h5 id="true-positive-metrics">3.True Positive metrics</h5>
<p>•TP衡量translation/scale/orientation/velocity/attribute errors</p>
<p>•所以TP矩阵计算匹配时都要满足center distance在2m之类</p>
<p>•最终计算平均在recall&gt;10%，达不到这个阈值某类的TP
errors所有都会被设置为1.</p>
<p>•Average Translation
error(ATE):bbox的中心到ego原点的L2范数(meters)。即公式</p>
<p><span class="math inline">\(\sqrt{ {(x1 - x2)^2} + {(y1 - y2)^2} +
{(z1 - z2)^2} }\)</span></p>
<p>. 区分于上面计算mAP作为阈值的distance:<span
class="math inline">\(\sqrt{(z1-z2)^2}\)</span></p>
<p>•Average Scale Error(ASE): 对齐中心和朝向之后计算1-IOU</p>
<p>•Average Orientation Error(AOE):最小的yaw
angle差异（radians）.一般类都是360度衡量，barriers在180度衡量，cones忽略这个指标。</p>
<p>•Average Velocity Error(AVE):absolute velocity error in
m/s.barrier和cone忽略这个指标。</p>
<p>•Average Attribute
Error(AAE):1-acc.acc是属性分类正确率。Barrier和cone忽略这个指标</p>
<p>•TP矩阵每个类分别计算，对于所有类别取均值得到Map,mASE,mAOE,mAVE,mAAE.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://77philosophia.github.io/2020/08/08/BaiduApi/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="philosophia">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garfield's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/08/BaiduApi/" class="post-title-link" itemprop="url">matlab调用百度API获取两地运输距离</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-08 22:21:10" itemprop="dateCreated datePublished" datetime="2020-08-08T22:21:10+08:00">2020-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-05-20 23:24:34" itemprop="dateModified" datetime="2024-05-20T23:24:34+08:00">2024-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1
id="matlab调用百度api获取两地运输距离">matlab调用百度API获取两地运输距离</h1>
<p>1、
首先你要去百度地图API注册一个ak,相当于钥匙，你在程序里会有个地方写这个ak，相当于钥匙，有这个ak百度地图才会跟你返回消息。</p>
<p>2、 获取距离的函数用python写的，<a
target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40450867/article/details/81098724">python版本获取距离</a>。我把它封装成了一个python类方便你从matlab里面传入参数。类输入就是两地的经度纬度。（注意先纬度再经度），注意19行ak要改为你自己申请的ak.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">from urllib.request import urlopen</span><br><span class="line">import urllib</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BaiduDistanceClass():</span><br><span class="line">    def __init__ (self,s1,s2,t1,t2):</span><br><span class="line">        self.s1 = str(s1)</span><br><span class="line">        self.s2 = str(s2)</span><br><span class="line">        self.t1 = str(t1)</span><br><span class="line">        self.t2 = str(t2)</span><br><span class="line">        </span><br><span class="line">    def getDistance(self):</span><br><span class="line">        a1=r&quot;http://api.map.baidu.com/routematrix/v2/driving?output=json&quot;</span><br><span class="line">        a2=r&quot;&amp;origins=&quot;+self.s1+&quot;,&quot;+self.s2</span><br><span class="line">        a3=r&quot;&amp;destinations=&quot;+self.t1+&quot;,&quot;+self.t2</span><br><span class="line">        a4=r&quot;&amp;coord_type=wgs84&quot;</span><br><span class="line">        a5=r&quot;&amp;tactics=11&quot;</span><br><span class="line">        a6=r&quot;&amp;ak=your_key&quot;</span><br><span class="line">        url=a1+a2+a3+a4+a5+a6</span><br><span class="line">        </span><br><span class="line">        b = urlopen(url)</span><br><span class="line">        c=b.read()</span><br><span class="line">        result = json.loads(c)</span><br><span class="line">        return result[&quot;result&quot;][0][&quot;distance&quot;][&quot;value&quot;]/1000</span><br></pre></td></tr></table></figure>
<p>3、总体思路用python获取结果然后在matlab获取python的返回结果。所以要电脑要同时有matlab和python的环境。弄完后在matlab命令行输入pyversion可以看到python的信息，就可以用了。<a
target="_blank" rel="noopener" href="https://www.ctolib.com/topics-125876.html">相关配置参考链接</a>。</p>
<p><img src="/2020/08/08/BaiduApi/pyversion.png" /></p>
<p>4、把获取距离的python文件和matlab当前运行文件放在同一个目录下。比如下图中我的获取距离的python文件也放在这个"助教"目录下。</p>
<p><img src="/2020/08/08/BaiduApi/目录.png" /></p>
<p>接下来你就可以在matlab里面调用python函数了。创建一个python类：</p>
<p><img src="/2020/08/08/BaiduApi/python.png" /></p>
<p>调用函数得到距离。这里s1,s2是源地点的纬度，经度；t1,t2是目标地点的纬度，经度。我这里测试用的上海和北京并在高德地图上面验证符合。</p>
<p><img src="/2020/08/08/BaiduApi/distance.png" /></p>
<p>注意这里得到的是公里，因为程序除了1000，API直接返回的是米，如果要以米为单位可以不除。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://77philosophia.github.io/2019/12/17/Object-Detection-Review/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="philosophia">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garfield's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/12/17/Object-Detection-Review/" class="post-title-link" itemprop="url">Object-Detection-Review</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-12-17 22:35:15" itemprop="dateCreated datePublished" datetime="2019-12-17T22:35:15+08:00">2019-12-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-05-20 22:36:11" itemprop="dateModified" datetime="2024-05-20T22:36:11+08:00">2024-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1
id="论文题目objection-detection-with-deep-learning-a-review">论文题目：Objection
Detection with Deep Learning: A Review</h1>
<h5 id="introduction">1.Introduction</h5>
<p>目标检测子类包括脸部检测(face detection)，行人检测(pedestrian
detection)，躯体骨骼检测(skeleton detection)等等。</p>
<p>目标检测的困难：在视角(viewpoints),姿势(poses),遮挡(occlusions),和光照条件(lightling
conditions)存在很大不同。</p>
<p>目标检测的任务<strong>=目标定位(object location)+目标分类(object
classification)</strong>。因此pipeline有三个阶段：<strong>目标区域选取(informative
region selection),特征提取(feature
extraction),分类(classification)</strong></p>
<h6 id="a.informative-region-selection">a.Informative region
selection</h6>
<p>解决方法是multi-scale sliding
window。因为你不知道目标会在图像的哪个位置出现，有多大。这个方法的缺点显而易见：expensive</p>
<h6 id="b.feature-extraction">b.feature extraction</h6>
<p>sift,hog算子等都可以用来提取物体特征，但是由于表面，光照，北京等影响很难设计一个具体的算子去特别识别一个目标。</p>
<h6 id="c.classification">c.classification</h6>
<p>比如SVM，AdaBoost, DPM</p>
<p>以上描述的传统算法缺点1、sliding window低效性。2、semantic gap cannot
be bridged by the low-level
descriptors.我们需要更为强大的特征提取算子。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://77philosophia.github.io/2019/12/06/paper-diggingInto/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="philosophia">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garfield's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/12/06/paper-diggingInto/" class="post-title-link" itemprop="url">paper-diggingInto</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-12-06 22:36:37" itemprop="dateCreated datePublished" datetime="2019-12-06T22:36:37+08:00">2019-12-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-05-20 23:13:03" itemprop="dateModified" datetime="2024-05-20T23:13:03+08:00">2024-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3
id="digging-into-self-supervised-monocular-depth-estimation论文阅读">《Digging
into Self-Supervised Monocular Depth Estimation》论文阅读</h3>
<h5 id="目标-self-supervised-monoculr-depth-estimation">目标：
self-supervised monoculr depth estimation</h5>
<h5 id="摘要">摘要：</h5>
<p>1、一个最小重投影损失，解决遮挡问题。</p>
<p>2、一个全分辨率多尺度取样方法，减少视觉误差。</p>
<p>3、一个自动遮挡损失，忽视违反相机运动假设的像素，不让其训练。</p>
<h5 id="损失函数">损失函数</h5>
<h5 id="重投影损失函数">1、重投影损失函数</h5>
<p><span class="math inline">\({L_p} =
\sum_{t^{&#39;}}pe(I_{t},I_{t^{&#39;}\rightarrow t})\)</span></p>
<p>其中 ： $pe(I_{a},I_{b})=(1-SSIM(I_{a},I_{b}))+（1-)||I_{a}-I_{b}|| $
目标就是相近的fram的appearance应该相同。pe是用来衡量两幅图的差距的。</p>
<p><span class="math inline">\(L_{s}=|\partial x d^{*}_{t}|e^{-|\partial
x I_t|} +|\partial y d^{*}_{t}|e^{-|\partial y I_t|}\)</span></p>
<h5 id="edge-aware-smoothness">2、edge-aware smoothness</h5>
<p>论文给出的解释是we can extract this interpretable depth from the
model. This is an ill-posed problem as there is an extremely large
number of possible incorrect depths per pixel which can correctly
reconstruct the novel view given the relative pose between those two
views.传统的双目和multi-view stereo方法通过enforcing smoothness in the
depth maps来解决，反正我不是很懂。</p>
<p><span class="math inline">\(L_{s}=|\partial x d^{*}_{t}|e^{-|\partial
x I_t|} +|\partial y d^{*}_{t}|e^{-|\partial y I_t|}\)</span></p>
<p>其中：<span
class="math inline">\(d^{*}_{t}=d_{t}/\bar{d_{t}}\)</span> ,
这样处理的目的是避免深度消失。</p>
<h5 id="对损失函数的提高">3、对损失函数的提高</h5>
<h6
id="a在目标frame和source-frame选择误差小的像素匹配这是为了拒绝被遮挡像素带来的误差增大的训练">a、在目标frame和source
frame选择误差小的像素匹配，这是为了拒绝被遮挡像素带来的误差增大的训练。</h6>
<p><img src="/2019/12/06/paper-diggingInto/appearance-loss.png" /></p>
<p>所以：$ L_{p}=min,pe(I_{t},I_{t^{'}t})$</p>
<h6 id="bauto-masking-stationary-pixels">b、Auto-Masking Stationary
Pixels</h6>
<p>self-supervised monocular training基于的假设是moving camera和static
scene。所以如果camera is static（比如车停下来画面不动）画面有object
motion（有其他车辆经过）就会有'holes' of infinite depth in depth
maps。针对这个问题作者提出一个mask。({0,1})</p>
<p>即reprojection error of the wraped image (I_{t^{'} t}) is lower than
that of the original, unwraped source image (I^{'}_{t}) .</p>
<p><span class="math inline">\(\mu =[min_{t^{&#39;}}\,
pe(I_{t},I_{t^{&#39;}\rightarrow {t}})&lt;min_{t}\,
pe(I_{t},I_{t^{&#39;}})]\)</span></p>
<p>原因是基于作者提出的两个分析：</p>
<p>（1）static camera 由same
pixels表明。所以这个时候(pe(I_{t},I_{t^{'}}))
几乎非常小，所以这种情况下可以把static camera去掉。</p>
<p>（2）一个moving object at equivalent relative translation to the
camera，or a low of pixels。</p>
<h6 id="cmulti-scale-estimation">c、Multi-scale Estimation</h6>
<p>为了解决bininear sampler带来的gradient locality，避免训练stuck in
local minima，现有模型通常采用的方法是multi-scale depth
prediction和image reconstruction。与其他人将input image 降到resolution
of each decoder不同，作者upsample the lower resolution depth
maps，然后reproject,resample这样去计算</p>
<h5 id="最终loss">4、最终Loss</h5>
<p><span class="math inline">\(L=\mu L_{p}+\lambda L_{s}\)</span></p>
<h5 id="其他考虑">5、其他考虑</h5>
<p>(1)depthnetwork总体是encoder-decoder结构。encoder是resnet18并且采用Pretrain
weights.decoder输出的深度的sigmoid值$$ 处理为depth.(D=) .</p>
<p>寻找这样的a,b使得D的范围在0.1~100units.</p>
<p>(2)pose network最后的输出会被scale by
0.01。同时虽然深度网络输入是三个连续的RGB图，pose
network的输入被处理为两幅RGB或者6个channel。相应的filter扩展一组，weights除以2.（维持filter的总和为1）.同时对输入图像进行了数据增强。horizontal
flips和color argumentation.</p>
<p>(3)输入图像大小为640*192. 损失函数中的() 取0.001。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://77philosophia.github.io/2019/08/06/dense-kitti-dataloader/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="philosophia">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garfield's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/06/dense-kitti-dataloader/" class="post-title-link" itemprop="url">dense-kitti-dataloader</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-06 23:17:10" itemprop="dateCreated datePublished" datetime="2019-08-06T23:17:10+08:00">2019-08-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-05-20 23:18:29" itemprop="dateModified" datetime="2024-05-20T23:18:29+08:00">2024-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="dense-kitti-dataloader">dense kitti dataloader</h2>
<p>这篇文章介绍kitti的稀疏深度图生成dense depth
map以及读出相应的dataloader，深度图的colormap可视化。主要用于深度估计。</p>
<h3 id="kitti-to-dense">kitti to dense</h3>
<h3 id="准备">准备</h3>
<p>KITTI的深度数据是sparse depth map，可以从官网下载到深度数据。<a
target="_blank" rel="noopener" href="http://www.cvlibs.net/datasets/kitti/eval_depth_all.php">original
depth map</a></p>
<p>KITTI的RGB数据用的是image_02。可以从官网下载到。<a
target="_blank" rel="noopener" href="http://www.cvlibs.net/datasets/kitti/raw_data.php">Raw
data</a>.这个可能要找代理服务器下载，我在网上看到也有人把数据迁移到国内服务器的。</p>
<p>由sparse depth map生成dense depth map的算法采用的是NYU的toolkit。<a
target="_blank" rel="noopener" href="https://github.com/jjhartmann/Toolbox-NYU-Depth-V2/blob/master/fill_depth_colorization.m">深度补全函数</a></p>
<h3 id="过程">过程</h3>
<p>新建一个文件夹，将深度解压的文件夹 data_depth_annotated
，原RGB数据RGB Raw的文件夹 raw_data_downloader，还有存放深度数据的文件夹
data_depth_to_dense放到一个目录下。说明：data_depth_to_dense
我就是把data_depth_annotated拷贝过来了，然后把文件名由data_depth_annotated改为data_depth_to_dense.因为反正图片数据要重写的，我拷贝的目的是不用重新建存放图片的目录。</p>
<p>准备三个文件夹下每张图片的路径存为三个csv文件。（写一个python脚本）</p>
<p>运行主程序 main.m。</p>
<h3 id="可视化">可视化</h3>
<p>可视化的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">im =cv2.imread(&#x27;image/path&#x27;)</span><br><span class="line">im_color = cv2.applyColorMap(im,cv2.COLORMAP_JET)</span><br></pre></td></tr></table></figure>
<p>来自这个链接：<a
target="_blank" rel="noopener" href="https://github.com/QianshengGu/KITTI_Dense_Depth.git">可视化</a></p>
<p>但是这个链接的kitti处理存放数据的时候采用最大最小值归一化，而不是存储的真实数据。一方面可能导致结果不太精确，另一方面导致ground
truth的深度值有零值存在，在输入深度网络训练的时候采用RMSE_log的损失的时候会导致损失函数无穷大。</p>
<h3 id="kitti-dataloader">kitti dataloader</h3>
<p>这个dataloader与我上面说的文件路径是一致的。</p>
<p>参考github我之后会放上去。</p>
<p>https://github.com/77philosophia/kitti_data_depth_loader</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">philosophia</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">36</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">philosophia</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
