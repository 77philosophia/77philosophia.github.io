<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"77philosophia.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="什么是langchin   image-20250104233619635  langchain是一个支持大语言模型相关应用开发的框架。 使得建设与ai相关的应用会更容易。  集成：将外部数据，比如文件、api、应用集成进来 代理：和环境集成  组件 - LangChain 使得更换必要的抽象和组件以使用语言模型变得轻而易举。 自定义链 - LangChain 提供现成的支持来使用和自定义“链”—">
<meta property="og:type" content="article">
<meta property="og:title" content="用lanchain做ai robot">
<meta property="og:url" content="http://77philosophia.github.io/2025/01/04/langchain-robot/index.html">
<meta property="og:site_name" content="Garfield&#39;s blog">
<meta property="og:description" content="什么是langchin   image-20250104233619635  langchain是一个支持大语言模型相关应用开发的框架。 使得建设与ai相关的应用会更容易。  集成：将外部数据，比如文件、api、应用集成进来 代理：和环境集成  组件 - LangChain 使得更换必要的抽象和组件以使用语言模型变得轻而易举。 自定义链 - LangChain 提供现成的支持来使用和自定义“链”—">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://77philosophia.github.io/2025/01/04/langchain-robot/image-20250104233619635.png">
<meta property="og:image" content="http://77philosophia.github.io/2025/01/04/langchain-robot/image-20250104233744531.png">
<meta property="og:image" content="http://77philosophia.github.io/2025/01/04/langchain-robot/image-20250104234107482.png">
<meta property="og:image" content="http://77philosophia.github.io/2025/01/04/langchain-robot/image-20250104234423043.png">
<meta property="og:image" content="http://77philosophia.github.io/2025/01/04/langchain-robot/image-20250104234750149.png">
<meta property="og:image" content="http://77philosophia.github.io/2025/01/04/langchain-robot/image-20250104235342635.png">
<meta property="article:published_time" content="2025-01-04T15:34:19.000Z">
<meta property="article:modified_time" content="2025-01-04T15:56:18.893Z">
<meta property="article:author" content="philosophia">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://77philosophia.github.io/2025/01/04/langchain-robot/image-20250104233619635.png">

<link rel="canonical" href="http://77philosophia.github.io/2025/01/04/langchain-robot/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>用lanchain做ai robot | Garfield's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Garfield's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://77philosophia.github.io/2025/01/04/langchain-robot/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="philosophia">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garfield's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          用lanchain做ai robot
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-01-04 23:34:19 / Modified: 23:56:18" itemprop="dateCreated datePublished" datetime="2025-01-04T23:34:19+08:00">2025-01-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="什么是langchin">什么是langchin</h3>
<figure>
<img src="/2025/01/04/langchain-robot/image-20250104233619635.png"
alt="image-20250104233619635" />
<figcaption aria-hidden="true">image-20250104233619635</figcaption>
</figure>
<p>langchain是一个支持大语言模型相关应用开发的框架。</p>
<p>使得建设与ai相关的应用会更容易。</p>
<ul>
<li><p>集成：将外部数据，比如文件、api、应用集成进来</p></li>
<li><p>代理：和环境集成</p></li>
</ul>
<p>组件 - LangChain
使得更换必要的抽象和组件以使用语言模型变得轻而易举。</p>
<p>自定义链 - LangChain
提供现成的支持来使用和自定义“链”——一系列串联在一起的操作。</p>
<p>速度 🚢 - 这个团队的交付速度非常快。您将会跟上最新的 LLM 功能。</p>
<p>社区 👥 - 极好的 Discord 和社区支持，见面会、黑客松等活动。</p>
<h2 id="llms">LLMs</h2>
<ul>
<li>公司开发和控制的专有模型：成本高、许可证限制、闭源</li>
<li>开源模型：开源、灵活性、可能缺乏大公司的支持和资源</li>
</ul>
<figure>
<img src="/2025/01/04/langchain-robot/image-20250104233744531.png"
alt="image-20250104233744531" />
<figcaption aria-hidden="true">image-20250104233744531</figcaption>
</figure>
<p>用api</p>
<p>AzureOpenAI:适用于一般的长文本生成任务，如小说写作、文章创作等。</p>
<p>AzureChatOpenAI:适用于涉及大量对话的文本生成任务，尤其是需要管理对话上下文时。</p>
<p>根据你的具体需求选择合适的模型。如果主要任务是长文本创作且对话不是主要部分，建议使用
AzureOpenAI。如果有大量对话且需要更好地管理对话上下文，建议使用
AzureChatOpenAI。</p>
<p>AzureOpenAI 会报错</p>
<p>Error code: 400 - {'error': {'code': 'OperationNotSupported',
'message': 'The completion operation does not work with the specified
model, gpt-4o. Please choose different model and try again. You can
learn more about which models can be used with each operation here:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#This basic example demostrate the LLM response and ChatModel Response</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> AzureOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> AzureChatOpenAI</span><br><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv, find_dotenv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the OpenAI library configuration using the retrieved environment variables</span></span><br><span class="line">OPENAI_API_TYPE = <span class="string">&quot;azure&quot;</span></span><br><span class="line">OPENAI_API_BASE = <span class="string">&quot;https://sparkopenai2024.openai.azure.com/&quot;</span></span><br><span class="line">OPENAI_API_VERSION = <span class="string">&quot;2024-02-15-preview&quot;</span></span><br><span class="line">OPENAI_API_KEY = <span class="string">&quot;xxx&quot;</span></span><br><span class="line">GPT4V_ENDPOINT = <span class="string">&quot;https://sparkopenai2024.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize an instance of AzureOpenAI using the specified settings</span></span><br><span class="line"><span class="comment"># llm = AzureOpenAI(</span></span><br><span class="line"><span class="comment">#     openai_api_version=OPENAI_API_VERSION,</span></span><br><span class="line"><span class="comment">#     openai_api_key=OPENAI_API_KEY,</span></span><br><span class="line"><span class="comment">#     openai_api_base=OPENAI_API_BASE,</span></span><br><span class="line"><span class="comment">#     openai_api_type=OPENAI_API_TYPE,</span></span><br><span class="line"><span class="comment">#     deployment_name=&quot;gpt-4o&quot;  # Name of the deployment for identification</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize an instance of AzureChatOpenAI using the specified settings</span></span><br><span class="line">chat_llm = AzureChatOpenAI(</span><br><span class="line">    openai_api_version=OPENAI_API_VERSION,</span><br><span class="line">    openai_api_key=OPENAI_API_KEY,</span><br><span class="line">    openai_api_base=OPENAI_API_BASE,</span><br><span class="line">    openai_api_type=OPENAI_API_TYPE,</span><br><span class="line">    deployment_name=<span class="string">&quot;gpt-4o&quot;</span>  </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the response from AzureOpenAI LLM for a specific question</span></span><br><span class="line"><span class="comment"># print(&quot;AzureOpenAI LLM Response: &quot;, llm(&quot; what is the weather in mumbai today?&quot;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the response from AzureChatOpenAI for the same question</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;AzureOpenAI ChatLLM Response: &quot;</span>, chat_llm.predict(<span class="string">&quot;what is the weather in mumbai today?&quot;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">如果直接与大模型交互-&gt;chatGPT。自从发现可以利</span><br><span class="line">用自有数据来增强大语言模型（LL</span><br><span class="line">M）的能力以来，如何将 LL</span><br><span class="line">M 的通用</span><br><span class="line">有效结合一直是热门话题。</span><br><span class="line">知识与个人数据</span><br><span class="line">1. 微调(finetue)</span><br><span class="line">2.</span><br><span class="line">RAG(检索增强)</span><br></pre></td></tr></table></figure>
<h3
id="先来考虑一个关于小说内容的chatrobot">先来考虑一个关于小说内容的chatRobot:</h3>
<figure>
<img src="/2025/01/04/langchain-robot/image-20250104234107482.png"
alt="image-20250104234107482" />
<figcaption aria-hidden="true">image-20250104234107482</figcaption>
</figure>
<p><strong>topic</strong>:</p>
<ul>
<li>文档分割</li>
<li>文档 <strong>Load</strong>：数据加载， <strong>LangChain</strong>
提供的 <strong>80</strong>
多种独特的加载器，以访问包括音频和视频在内的各种数据源。</li>
<li>向量存储和嵌入：深入了解嵌入的概念，探索 <strong>LangChain</strong>
中的向量存储集成。</li>
<li>检索：掌握在 <strong>Vector</strong>
存储中访问和索引数据的高级技术，使您能够检索语义查询之外的最相关信息。</li>
<li>问题解答：构建一次性问题解答解决方案<strong>/</strong>总结方案。</li>
</ul>
<h4 id="long-text-summarisation">Long text summarisation</h4>
<h5 id="为什么context-window会是limit">为什么context
window会是limit</h5>
<p>当前大多数的语言模型是基于解码器的模型。这些模型使用了变换器架构中的解码器部分来预测下一个标记的概率。然后，将这个预测的标记附加到输入文本中，形成预测下一个标记的输入。</p>
<p><strong>Context Window Size = Input Sequence Length + Prompt Length +
O</strong></p>
<p><strong>utput Sequence Length</strong></p>
<figure>
<img src="/2025/01/04/langchain-robot/image-20250104234423043.png"
alt="image-20250104234423043" />
<figcaption aria-hidden="true">image-20250104234423043</figcaption>
</figure>
<p>举个例子：如果context window的限制是4097，prompt的token
size是50，期待输出的总结内容是200，那么最大的输入文本的token
size就是4097-50-200=3847tokens，大概对应3000个词。</p>
<blockquote>
<p>[!IMPORTANT]</p>
<p>LLMs受限于固定的上下文窗口，比如chatgpt的limit
tokens是4096，大概对应3000多个词。对于这个问题有两种解决方案：第一种用更大context
window的LLMs;第二种方法是化整为零，将长文本分成很多个短文本，分别送进模型处理然后合并，或者选择最相关的部分然后送进去分析。</p>
</blockquote>
<figure>
<img src="/2025/01/04/langchain-robot/image-20250104234750149.png"
alt="image-20250104234750149" />
<figcaption aria-hidden="true">image-20250104234750149</figcaption>
</figure>
<p>文档分割：</p>
<p>CharacterTextSplitter:直接按字符数量分割文本。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">c_splitter = CharacterTextSplitter(</span><br><span class="line">    chunk_size=chunk_size,</span><br><span class="line">    chunk_overlap=chunk_overlap,</span><br><span class="line">    separator = &#x27; &#x27;    //主要在哪一块分割</span><br><span class="line">)</span><br><span class="line">c_splitter.split_text(text3)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><p>RecursiveCharacterTextSplitter: 按照递归规则分割文本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">r_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=150,</span><br><span class="line">    chunk_overlap=0,</span><br><span class="line">    separators=[&quot;\n\n&quot;, &quot;\n&quot;, &quot;(?&lt;=\. )&quot;, &quot; &quot;, &quot;&quot;]</span><br><span class="line">)</span><br><span class="line">r_splitter.split_text(some_text)</span><br></pre></td></tr></table></figure></li>
<li><p>TokenTextSplitter：跟LLMs里的token的概念对齐</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)</span><br></pre></td></tr></table></figure></li>
<li><p>Context aware splitting</p></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from langchain.document_loaders import NotionDirectoryLoader</span><br><span class="line">from langchain.text_splitter import MarkdownHeaderTextSplitter</span><br><span class="line"></span><br><span class="line">markdown_document = &quot;&quot;&quot;# Title\n\n \</span><br><span class="line">## Chapter 1\n\n \</span><br><span class="line">Hi this is Jim\n\n Hi this is Joe\n\n \</span><br><span class="line">### Section \n\n \</span><br><span class="line">Hi this is Lance \n\n </span><br><span class="line">## Chapter 2\n\n \</span><br><span class="line">Hi this is Molly&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">headers_to_split_on = [</span><br><span class="line">    (&quot;#&quot;, &quot;Header 1&quot;),</span><br><span class="line">    (&quot;##&quot;, &quot;Header 2&quot;),</span><br><span class="line">    (&quot;###&quot;, &quot;Header 3&quot;),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">markdown_splitter = MarkdownHeaderTextSplitter(</span><br><span class="line">    headers_to_split_on=headers_to_split_on</span><br><span class="line">)</span><br><span class="line">md_header_splits = markdown_splitter.split_text(markdown_document)</span><br></pre></td></tr></table></figure>
<h3 id="rag搜索增强">RAG搜索增强</h3>
<figure>
<img src="/2025/01/04/langchain-robot/image-20250104235342635.png"
alt="image-20250104235342635" />
<figcaption aria-hidden="true">image-20250104235342635</figcaption>
</figure>
<blockquote>
<p>[!NOTE]</p>
<p><strong>query</strong>和<strong>prompt</strong>的区别是什么？</p>
<p>在使用 <strong>RetrievalQA chain</strong> 进行问答时， prompt 和
query
是两个不同的概念。理解它们的区别对于构建有效的问答系统非常重要。</p>
<ol type="1">
<li><strong>Query（查询）</strong> ：</li>
</ol>
<p>◦ query 是用户提出的问题或查询。例如，“<strong>What is the capital of
France?</strong>”</p>
<p>◦ 在 qa_chain_mr 中， query
是必须的，因为它是整个问答流程的起点。系统根据 query
去检索相关的文档，然后从中抽取答</p>
<p>案。</p>
<ol start="2" type="1">
<li><strong>Prompt（提示词）</strong> ：</li>
</ol>
<p>◦ prompt
是用于指导语言模型生成答案的额外文本或上下文。它可以包含特定的指示或格式化信息，以帮助模型生成更合适的响应。</p>
<p>提供prompt可以帮助模型更好地理解上下文或期望的回答形式。例如，你可以提供一个
prompt 来指示模型回答时的语气、详细程度或者其他特定要求。</p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/01/04/aigc-paper-share/" rel="prev" title="AIGC论文reading">
      <i class="fa fa-chevron-left"></i> AIGC论文reading
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/01/05/ai-scaler/" rel="next" title="ai-scaler">
      ai-scaler <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFlangchin"><span class="nav-number">1.</span> <span class="nav-text">什么是langchin</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#llms"><span class="nav-number"></span> <span class="nav-text">LLMs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%88%E6%9D%A5%E8%80%83%E8%99%91%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8E%E5%B0%8F%E8%AF%B4%E5%86%85%E5%AE%B9%E7%9A%84chatrobot"><span class="nav-number">1.</span> <span class="nav-text">先来考虑一个关于小说内容的chatRobot:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#long-text-summarisation"><span class="nav-number">1.1.</span> <span class="nav-text">Long text summarisation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88context-window%E4%BC%9A%E6%98%AFlimit"><span class="nav-number">1.1.1.</span> <span class="nav-text">为什么context
window会是limit</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rag%E6%90%9C%E7%B4%A2%E5%A2%9E%E5%BC%BA"><span class="nav-number">2.</span> <span class="nav-text">RAG搜索增强</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">philosophia</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">45</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">philosophia</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
